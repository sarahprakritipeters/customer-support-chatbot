### Customer Support Chatbot for PartsSelect website

Given the PartsSelect website, build an agentic framework to support use queries related to refirgerators, dishwashers, and transactions. 

#### Technology Used 

Retrieval Augmented Generation (RAG) --> Large Language Models are trained on vast amounts of data so that they can handle any question-answering tasks. RAG uses LLMs to handle question answering in a limited scope, by creating a knowledge base on a specific domain. Given limited code resources, my aim was to create a knowledge base of the most popular or frequently visited pages related to Refrigerators and dishwashers on this site. 

#### WEB SCRAPING -- Scraper.ipynb
(Packages: BeautifulSoup)

This file is used to create CSV files of the popular fridge and dishwasher parts. This files includes 3 functions: 
1. Get_fridge_details/Get_dishwasher_details - Both functions extract important information such as titles, descriptions, prices, stock, part numbers, manufacturer information and related links
2. Pull_product_specs - Extracts important information such as customer ratings, ease of repair ratings, symptoms fixed by a part, etc
3. qna - Extracts FAQs related to popular fridge and dishwasher parts

Issues I faced: 

    1. Extracting the parts that are replacements for the current product was difficult because the same tag was used in the HTML code
    2. Extracting model number for each query on a product page was difficult to store

Scraper.py outputs 2 CSV files on fridge and dishwasher appliances. 

### Building a Basic Chatbot -- customer_support_chatbot.ipynb

This file sets up a customer support chatbot that pulls information from important links and the CSV files generated by the web scraper. This data is split into chunks of information, which is then embedded and stored in a vector store. Langchain is used to set up a RAG system that extracts information from the vector store and answers questions realted to customer queries. 

Issues I faced:

    1. How do I feed in my knowledge base?
    2. Testing for spelling mistakes in the queries

#### Setting up the Backend - backend.py

This file contains the same code as customer_support_chatbot along with a Flask setup to connect to the frontend code (as provided by Instalily). The backend code invokes the RAG chain for every incoming query and returns an output based on context stored in the vector store. 

#### Extensibility and Scalability

1. The Scraper can be used to frequently update and store popular appliances data - it is also easy to modify to add additional appliances. 
2. The biggest part of scaling the backend is by increasing the context stored in the vector store. This can be achieved by adding more links to the WebBaseLoader.
3. The large language model used here is GPT-3.5, since it is a hyperparameter, we can use multiple LLMs
